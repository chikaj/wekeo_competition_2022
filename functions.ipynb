{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all packages are installed\n",
    "# %conda install -c conda-forge rasterio cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for data segmentation and attribution\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "from skimage.segmentation import slic, felzenszwalb, watershed, quickshift\n",
    "from skimage.filters import sobel\n",
    "from skimage.morphology import diamond, disk, rectangle, square, star, octagon\n",
    "from skimage.filters.rank import modal\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.measure import label, regionprops\n",
    "from collections import OrderedDict\n",
    "from geopandas import GeoDataFrame\n",
    "from rasterstats import zonal_stats\n",
    "from affine import Affine\n",
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from rasterio.plot import show, show_hist\n",
    "from skimage import img_as_float, exposure\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy import config\n",
    "\n",
    "# Imports for coordinate conversion...for cartopy\n",
    "from pyproj import Transformer\n",
    "utm2wgs = Transformer.from_crs(32632, 4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAFXRFWHRUaXRsZQBteWNtYXAgY29sb3JtYXBbv6KmAAAAG3RFWHREZXNjcmlwdGlvbgBteWNtYXAgY29sb3JtYXASKLpCAAAAMHRFWHRBdXRob3IATWF0cGxvdGxpYiB2My41LjIsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmfCWnicAAAAMnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHYzLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZ+z857sAAAHESURBVHic7dZBToNAAEDRQbvwBN7T+6fiomoCDVKM1cT/3mZCZ4ahLNo/Pb08z2OMMcb7MI3FOK2uxzTvzC/Xbc9/7F+dO9bzv3z+6jn+7PxpeXm/8y/jwzg2TgfX/9T42+f+9/Pm+XLi6/z49TiW1+fP+dNN+88b97l53+5znY7t27jP0X1X6zee5/D32n3ve+NpuX7jvX/87G/bW7D8+zi6f1rPXy2/8fzNjw+ef3Wfb56/nt9Ytnv+nd7P+ncGAAgRAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACC3gB8PZ233MSjYwAAAABJRU5ErkJggg==\n",
      "text/html": [
       "<div style=\"vertical-align: middle;\"><strong>mycmap</strong> </div><div class=\"cmap\"><img alt=\"mycmap colormap\" title=\"mycmap\" style=\"border: 1px solid #555;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAFXRFWHRUaXRsZQBteWNtYXAgY29sb3JtYXBbv6KmAAAAG3RFWHREZXNjcmlwdGlvbgBteWNtYXAgY29sb3JtYXASKLpCAAAAMHRFWHRBdXRob3IATWF0cGxvdGxpYiB2My41LjIsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmfCWnicAAAAMnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHYzLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZ+z857sAAAHESURBVHic7dZBToNAAEDRQbvwBN7T+6fiomoCDVKM1cT/3mZCZ4ahLNo/Pb08z2OMMcb7MI3FOK2uxzTvzC/Xbc9/7F+dO9bzv3z+6jn+7PxpeXm/8y/jwzg2TgfX/9T42+f+9/Pm+XLi6/z49TiW1+fP+dNN+88b97l53+5znY7t27jP0X1X6zee5/D32n3ve+NpuX7jvX/87G/bW7D8+zi6f1rPXy2/8fzNjw+ef3Wfb56/nt9Ytnv+nd7P+ncGAAgRAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACCBAAABAkAAAgSAAAQJAAAIEgAAECQAACAIAEAAEECAACC3gB8PZ233MSjYwAAAABJRU5ErkJggg==\"></div><div style=\"vertical-align: middle; max-width: 514px; display: flex; justify-content: space-between;\"><div style=\"float: left;\"><div title=\"#087116ff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #087116ff;\"></div> under</div><div style=\"margin: 0 auto; display: inline-block;\">bad <div title=\"#00000000\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #00000000;\"></div></div><div style=\"float: right;\">over <div title=\"#0e6dbdff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #0e6dbdff;\"></div></div>"
      ],
      "text/plain": [
       "<matplotlib.colors.LinearSegmentedColormap at 0x7fef1f3cc3a0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['forest', 'grassland-green', 'grassland-light', 'lake-deep', 'lake-sediment']\n",
    "bounds = [1, 2, 3, 4, 5]\n",
    "color_list = ['#087116', '#18ad0a', '#93ad0a', '#0a74cd', '#0e6dbd',]\n",
    "\n",
    "def bin_mapping(x):\n",
    "    for idx, bound in enumerate(bounds):\n",
    "        if x < bound:\n",
    "            return idx / (len(bounds) - 1.0)\n",
    "\n",
    "bin_labels = [idx / (len(bounds) - 1.0) for idx in range(len(bounds))]\n",
    "\n",
    "lc_cmap = LinearSegmentedColormap.from_list('mycmap', [(lbl, color) for lbl, color in zip(bin_labels, color_list)])\n",
    "\n",
    "lc_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for classification and accuracy assessment\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bsq_to_bip(image):\n",
    "    # no error checking yet...\n",
    "    return  image.transpose(1, 2, 0)\n",
    "\n",
    "\n",
    "def bip_to_bsq(image):\n",
    "    # no error checking yet...\n",
    "    return  image.transpose(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(image=None, transform=None, crs=None):\n",
    "    \"\"\"\n",
    "    Raster-to-Vector conversion.\n",
    "    \n",
    "    Performs a raster-to-vector conversion of a classified image. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image: numpy.array\n",
    "        A signle band of (classified, ideally) image data where the pixel\n",
    "        values are integers. Shape is (1, rows, columns). This parameter is\n",
    "        optional.\n",
    "    \n",
    "    transform: rasterio.transform\n",
    "        A raster transform used to convert row/column values to geographic\n",
    "        coordinates. This parameter is optional.\n",
    "\n",
    "    crs: rasterio.crs\n",
    "        A proj4 string representing the coordinate reference system. \n",
    "        This parameter is optional.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    GeoDataFrame\n",
    "        A vector version of the classified raster.\n",
    "    \"\"\"\n",
    "\n",
    "    img = image[0].astype(np.int32)\n",
    "        \n",
    "    shps = features.shapes(img, transform=transform)\n",
    "    records = []\n",
    "\n",
    "    for id, shp in enumerate(shps):\n",
    "        if shp[1] != 0:\n",
    "            item = {'geometry': shp[0], 'id': id+1, 'properties': \n",
    "                    OrderedDict([('dn', np.int32(shp[1]))]),\n",
    "                    'type': 'Feature'}\n",
    "            records.append(item)\n",
    "\n",
    "    vec = GeoDataFrame.from_features(records)\n",
    "    vec.crs = crs\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_zonal_properties(image=None, transform=None,\n",
    "                         band_names=['red','green','blue'], stats=['mean'],\n",
    "                         gdf=None):\n",
    "    \"\"\"\n",
    "    Adds zonal properties to a GeoDataFrame.\n",
    "    \n",
    "    Adds zonal properties to a GeoDataFrame, where the statistics 'stats' are\n",
    "    calculated for all pixels within the geographic objects boundaries.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image: numpy.array\n",
    "        A signle band of (classified, ideally) image data where the pixel\n",
    "        values are integers. Shape is (1, rows, columns). This parameter is\n",
    "        optional.\n",
    "    \n",
    "    transform: rasterio.transform\n",
    "        A raster transform used to convert row/column values to geographic\n",
    "        coordinates. This parameter is optional.\n",
    "    \n",
    "    band_names: list of strings\n",
    "        The labels corresponding to each band of the src or image. \n",
    "    \n",
    "    stats: list of strings\n",
    "        The list of zonal statistics to calculate for each geographic object.\n",
    "        The full list of stats is: ['sum', 'std', 'median', 'majority',\n",
    "        'minority', 'unique', 'range', 'nodata', 'percentile_<q>']. Replace\n",
    "        <q> with a value between 1 and 100, inclusive.\n",
    "    \n",
    "    gdf: GeoDataFrame\n",
    "        The GeoDataFrame to be updated with zonal statistics. The number of\n",
    "        columns that will be added is equal to len(bands) * len(stats). \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    GeoDataFrame\n",
    "        A GeoDataFrame with the zonal statistics added as new columns. \n",
    "    \"\"\"\n",
    "    if len(image.shape) > 2:\n",
    "      if len(image) != len(band_names): \n",
    "          print(\"The number of bands must equal the number of bands_names.\")\n",
    "          return None\n",
    "    else:\n",
    "      if len(band_names) != 1:\n",
    "        print(\"You do not have the correct number of band_names.\")\n",
    "        return None\n",
    "\n",
    "    if len(image.shape) > 2:\n",
    "        for band, name in enumerate(band_names):\n",
    "            raster_stats = zonal_stats(gdf, image[band], stats=stats,\n",
    "                                       nodata=np.nan, affine=transform)\n",
    "          \n",
    "            fields = [[] for i in range(len(stats))]\n",
    "            labels = []\n",
    "\n",
    "            for i, rs in enumerate(raster_stats):\n",
    "                for j, r in enumerate(rs):\n",
    "                    if i == 0:\n",
    "                        labels.append(r)\n",
    "                    fields[j].append(rs[r])\n",
    "\n",
    "            for i, l in enumerate(labels):\n",
    "                gdf.insert(len(gdf.columns)-1, name + \"_\" + l, fields[i])\n",
    "    else:\n",
    "        raster_stats = zonal_stats(gdf, image, stats=stats,\n",
    "                                   nodata=np.nan, affine=transform)\n",
    "\n",
    "        fields = [[] for i in range(len(stats))]\n",
    "        labels = []\n",
    "      \n",
    "        for i, rs in enumerate(raster_stats):\n",
    "            for j, r in enumerate(rs):\n",
    "                if i == 0:\n",
    "                    labels.append(r)\n",
    "                fields[j].append(rs[r])\n",
    "      \n",
    "        for i, l in enumerate(labels):\n",
    "            gdf.insert(len(gdf.columns)-1, band_names[0] + \"_\" + l, fields[i])\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prop(props, label):\n",
    "    for p in props:\n",
    "        if p.label == label:\n",
    "            return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_shape_properties(classified_image, gdf, attributes=['area', 'perimeter']):\n",
    "    \"\"\"\n",
    "    Add raster properties as vector fields.\n",
    "    \n",
    "    POSSIBLE IMPROVEMENT!! REMOVE PARAMETER classified_image AND INSTEAD USE \n",
    "    rasterize TO RASTERIZE THE gdf. \n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    classified_image: numpy.array\n",
    "        A 2D image with integer, class-based, values.\n",
    "    \n",
    "    gdf: GeoDataFrame\n",
    "        A GeoDataFrame (vector) with object boundaries corresponding to image\n",
    "        regions. Image attributes will be assigned to each vector object.\n",
    "    \n",
    "    attributes: list of strings\n",
    "        attributes is a list of strings where each string is a type of shape to\n",
    "        calculate for each polygon. Possible shapes include: area, bbox_area,\n",
    "        centroid, convex_area, eccentricity, equivalent_diamter, euler_number,\n",
    "        extent, filled_area, label, maxor_axis_length, max_intensity,\n",
    "        mean_intensity, min_intensity, minor_axis_length, orientation,\n",
    "        perimeter, or solidity.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Nothing\n",
    "        Instead modifies GeoDataFrame in place.\n",
    "    \"\"\"\n",
    "    clim = classified_image[0, :, :]\n",
    "    props = regionprops(clim)\n",
    "    \n",
    "    attributes = {s: [] for s in attributes}\n",
    "\n",
    "    for row in gdf.itertuples():\n",
    "        rid = getattr(row, 'dn')\n",
    "        \n",
    "        p = get_prop(props, rid)\n",
    "        if p is not None:\n",
    "            for a in attributes:\n",
    "                attributes[a].append(getattr(p, a))\n",
    "\n",
    "    try:\n",
    "        for a in attributes:\n",
    "            if (a == 'area'):\n",
    "                gdf.insert(len(gdf.columns)-1, a, gdf.geometry.area)\n",
    "            elif (a == 'perimeter'):\n",
    "                gdf.insert(len(gdf.columns)-1, a, gdf.geometry.length)\n",
    "            else:\n",
    "                gdf.insert(len(gdf.columns)-1, a, attributes[a])\n",
    "    except:\n",
    "        print(\"The geometry is bad for this gdf.\")\n",
    "        print(gdf.columns)\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_edge_detect(image=None, mask=None):\n",
    "    \"\"\"\n",
    "    Performs a Sobel edge detection.\n",
    "\n",
    "    Performs a Sobel edge detection on a 2D image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image: numpy.array\n",
    "        A rasterio-style image. The image is any single band obtained by: \n",
    "            image = src.read(band, masked=True), where band is an integer.\n",
    "        This parameter is optional.\n",
    "            \n",
    "    mask: numpy.array\n",
    "        A rasterio-style image. The image is any single band obtained by: \n",
    "            image = src.read_masks(1), where band is an integer. \n",
    "        This parameter is optional.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.array\n",
    "        A single band, rasterio-style image ([band][row][column]).\n",
    "    \"\"\"\n",
    "    # image = image\n",
    "    # mask[mask > 255] = 1\n",
    "        \n",
    "    edges = sobel(image)\n",
    "    return bip_to_bsq(edges[:, :, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(image=None, mask=None, model=None, params=None,\n",
    "                 modal_footprint=np.zeros(1), sieve_size=None):\n",
    "    \n",
    "# modal_radius=None, # old parameter...delete when known not needed\n",
    "    \"\"\"\n",
    "    Segment the image.\n",
    "\n",
    "    Segment the image using an algorithm from sklearn.segmentation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: skimage.segmentation model\n",
    "        A model from skimage.segmentation (e.g., slic, slic0, felzenswalb)\n",
    "\n",
    "    params: sklearn.segmentation model parameters\n",
    "        The unique parameters for the selected segmentation algorithm. Will be\n",
    "        passed to the model as the kwargs argument.\n",
    "        \n",
    "    image: numpy.array\n",
    "        A 3-band (RGB) image used for segmentation. The shape of the image\n",
    "        must be ordered as follows: (bands, rows, columns).\n",
    "        This parameter is optional.\n",
    "    \n",
    "    mask: numpy.array\n",
    "        A 1-band image mask. The shape of the mask must be ordered as follows:\n",
    "        (rows, columns). This parameter is optional.\n",
    "    \n",
    "    modal_radius: integer\n",
    "        Integer representing the radius of a raster disk (i.e., circular\n",
    "        roving window). Optional. If not set, no modal filter will be applied.\n",
    "        \n",
    "    modal_footprint: skimage.morphology 2D shape\n",
    "        A diamond, disk, rectangle, square, or octagon function that returns\n",
    "        a kernel shaped according to the specific function\n",
    "    \n",
    "    sieve_size: integer\n",
    "        An integer representing the smallest number of pixels that will be\n",
    "        included as a unique segment. Segments this size or smaller will be\n",
    "        merged with the neighboring segment with the most pixels. Optional. \n",
    "        If not set, no modal filter will be applied.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.array\n",
    "        A numpy array arranged as rasterio would read it (bands=1, rows, cols)\n",
    "        so it's ready to be written by rasterio\n",
    "\n",
    "    \"\"\"\n",
    "    if model.__name__ == 'watershed':\n",
    "      if len(image.shape) > 2:\n",
    "        print(f\"Image has too many dimensions for watershed segmentation.\")\n",
    "        print(\"This will cause errors. Create a grayscale image before preceeding. Exiting.\")\n",
    "        return\n",
    "      else:\n",
    "        img = image\n",
    "    else:\n",
    "        img = bsq_to_bip(image)\n",
    "\n",
    "    output = model(img, **params).astype('int32')\n",
    "\n",
    "    while np.ndarray.min(output) < 1:\n",
    "        output += 1\n",
    "\n",
    "    # if modal_radius != None:\n",
    "    #     output = modal(output.astype('int16'), footprint=disk(modal_radius))\n",
    "        \n",
    "    if modal_footprint.any():\n",
    "        output = modal(output.astype('int16'), footprint=modal_footprint)\n",
    "\n",
    "    if sieve_size != None:\n",
    "        output = features.sieve(output, sieve_size)\n",
    "    \n",
    "    output = bip_to_bsq(output[:, :, np.newaxis])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_composite(image, red_band, green_band, blue_band):\n",
    "    my_red = image[red_band]\n",
    "    my_green = image[green_band]\n",
    "    my_blue = image[blue_band]\n",
    "    return np.stack([my_red, my_green, my_blue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
